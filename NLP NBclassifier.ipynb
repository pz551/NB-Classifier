{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram accuracy: 0.89453125\n"
     ]
    }
   ],
   "source": [
    "#Read data from training set\n",
    "def readData(fileName):\n",
    "    words = []\n",
    "    file = open(fileName, \"r\")\n",
    "\n",
    "    for word in file.read().split():\n",
    "      words.append(word)\n",
    "\n",
    "    file.close()\n",
    "    return words\n",
    "\n",
    "#Read data from test set\n",
    "def readTestFile(fileName):\n",
    "  reviews = []\n",
    "  file = open(fileName, \"r\")\n",
    "  lines = file.readlines()\n",
    "\n",
    "  for line in lines:\n",
    "      reviews.append(line)\n",
    "\n",
    "  file.close()\n",
    "  return reviews\n",
    "\n",
    "\n",
    "#Create n-gram features for the data\n",
    "#Comment out the unwanted features\n",
    "def create_ngram_features(words):\n",
    "    unigram_vocab = ngrams(words, 1)\n",
    "    bigram_vocab = ngrams(words, 2)\n",
    "    trigram_vocab = ngrams(words, 3)\n",
    "    quadgram_vocab = ngrams(words, 4)\n",
    "    pentagram_vocab = ngrams(words, 5)\n",
    "    \n",
    "    my_dict = {}\n",
    "\n",
    "    for ng in unigram_vocab:\n",
    "        if ng in my_dict:\n",
    "            my_dict[ng] = my_dict[ng] + 1\n",
    "        else:\n",
    "            my_dict[ng] = 1\n",
    "    for ng in bigram_vocab:\n",
    "        if ng in my_dict:\n",
    "            my_dict[ng] = my_dict[ng] + 1\n",
    "        else:\n",
    "            my_dict[ng] = 1\n",
    "    for ng in trigram_vocab:\n",
    "        if ng in my_dict:\n",
    "            my_dict[ng] = my_dict[ng] + 1\n",
    "        else:\n",
    "            my_dict[ng] = 1 \n",
    "    for ng in quadgram_vocab:\n",
    "        if ng in my_dict:\n",
    "            my_dict[ng] = my_dict[ng] + 1\n",
    "        else:\n",
    "            my_dict[ng] = 1\n",
    "    for ng in pentagram_vocab:\n",
    "        if ng in my_dict:\n",
    "            my_dict[ng] = my_dict[ng] + 1\n",
    "        else:\n",
    "            my_dict[ng] = 1\n",
    "            \n",
    "    my_dict.update({'total_word_count':len(words)})\n",
    "    return my_dict\n",
    "\n",
    "#Reading the test file\n",
    "test = readTestFile(\"DATASET/test/test.txt\")\n",
    "\n",
    "#Constructing the bigram model for truthful corpus\n",
    "truthful = readTestFile(\"DATASET/train/truthful.txt\")   \n",
    "\n",
    "#Constructing the bigram model for deceptive corpus\n",
    "deceptive = readTestFile(\"DATASET/train/deceptive.txt\") \n",
    "\n",
    "#Classify the test corpus with existing Language Models\n",
    "truthfulVal = readTestFile(\"DATASET/validation/truthful.txt\")\n",
    "deceptiveVal = readTestFile(\"DATASET/validation/deceptive.txt\")\n",
    "\n",
    "\n",
    "truthful_data = []\n",
    "for truthful_reviews in truthful:\n",
    "  words = truthful_reviews.split()\n",
    "  truthful_data.append((create_ngram_features(words), \"truthful\"))    \n",
    "\n",
    "deceptive_data = []\n",
    "for deceptive_reviews in deceptive:\n",
    "  words = deceptive_reviews.split()\n",
    "  deceptive_data.append((create_ngram_features(words), \"deceptive\"))    \n",
    "\n",
    "\n",
    "truthful_val_data = []\n",
    "for truthful_reviews in truthfulVal:\n",
    "  words = truthful_reviews.split()\n",
    "  truthful_val_data.append((create_ngram_features(words), \"truthful\"))    \n",
    "\n",
    "deceptive_val_data = []\n",
    "for deceptive_reviews in deceptiveVal:\n",
    "  words = deceptive_reviews.split()\n",
    "  deceptive_val_data.append((create_ngram_features(words), \"deceptive\")) \n",
    "\n",
    "train_set = truthful_data + deceptive_data\n",
    "test_set =  truthful_val_data + deceptive_val_data\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "accuracy = nltk.classify.util.accuracy(classifier, test_set)\n",
    "print('n-gram accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read test data\n",
    "test_data = []\n",
    "for reviews in test:\n",
    "  words = reviews.split()\n",
    "  test_data.append((create_ngram_features(words))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute test results\n",
    "list_results = []\n",
    "truth_review = 0\n",
    "for i in range(len(test_data)):\n",
    "    result = classifier.classify(test_data[i])\n",
    "    if result == 'truthful':\n",
    "        truth_review += 1\n",
    "    list_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output csv document for prediction\n",
    "with open(\"Prediction6.csv\", \"w\") as file:\n",
    "    index = 0\n",
    "    for review in list_results:\n",
    "        if review == 'truthful':\n",
    "            file.write(\"\" + str(index) + \", 0 \\n\")\n",
    "        else:\n",
    "            file.write(\"\" + str(index) + \", 1 \\n\")\n",
    "        index+=1\n",
    "\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
